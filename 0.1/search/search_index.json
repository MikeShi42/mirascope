{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started with Mirascope","text":"<p>This library intends to give developers a better way to build with LLMs that integrates seamlessly into your workflow, starting with better prompt management and core LLM interaction calls. We\u2019re building the de facto pythonic prompt templating and LLM-interaction library.</p> <p> </p>"},{"location":"#why-use-mirascope","title":"Why use Mirascope?","text":"<ul> <li>Easy: Designed for ease of use, Mirascope features an intuitive interface and a minimal learning curve</li> <li>Intuitive: Get editor support for prompts, eliminating the need to dig through documentation</li> <li>Durable: Mirascope offers versatile and adaptable functionality, allowing seamless integration with custom solutions</li> <li>Integration: Leveraging Pydantic, Mirascope offers easy integration with JSON Schema and other tools</li> <li>Maintainability: Reduce prompt-related bugs and organize prompts with provided utilities</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>Install Mirascope and start building with LLMs in minutes.</p> <pre><code>$ pip install mirascope\n</code></pre> <p>This will install the <code>mirascope</code> package and CLI.</p>"},{"location":"#a-simple-mirascope-example","title":"A Simple Mirascope Example","text":"<pre><code>from mirascope import OpenAIChat, Prompt\n\nclass BookRecommendationPrompt(Prompt):\n    \"\"\"\n    Can you recommend some books on {topic}?\n    \"\"\"\n\n    topic: str\n\nprompt = BookRecommendationPrompt(topic=\"coding\")\nprint(str(prompt))\n\nmodel = OpenAIChat(api_key=os.getenv(\"OPENAI_API_KEY\"))\nres = model.create(prompt)\nprint(str(res))\n</code></pre> <pre><code>Can you recommend some books on coding?\n\nCertainly! Here are some highly recommended books on coding: ...\n</code></pre>"},{"location":"#dive-deeper","title":"Dive Deeper","text":"<ul> <li>Check out the concepts section to dive deeper into the library and the core features that make it powerful, such as pydantic prompts and the Mirascope CLI.</li> <li>You can follow along with more detailed examples to get a better understanding of how to utilize the library to effectively model your data. You can also take a look at code examples in the repo.</li> <li>The API Reference contains full details on all classes, methods, functions, etc.</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>Mirascope welcomes contributions from the community! See the contribution guide for more information on the development workflow. For bugs and feature requests, visit our GitHub Issues and check out our templates.</p>"},{"location":"#how-to-help","title":"How To Help","text":"<p>Any and all help is greatly appreciated! Check out our page on how you can help.</p>"},{"location":"#roadmap-whats-on-our-mind","title":"Roadmap (What's on our mind)","text":"<ul> <li> Agents</li> <li> RAG</li> <li> Functions as OpenAI tools</li> <li> Testing for prompts</li> <li> Add more LLMs</li> <li> Prompt Response tracking</li> <li> Database support for versioning</li> <li> Better DX for Mirascope CLI (e.g. autocomplete)</li> </ul>"},{"location":"#versioning","title":"Versioning","text":"<p>Mirascope uses Semantic Versioning.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the terms of the MIT License.</p>"},{"location":"CONTRIBUTING/","title":"Contributing","text":""},{"location":"CONTRIBUTING/#setting-up-development-environment","title":"Setting Up Development Environment","text":"<p>We use poetry as our package and dependency manager.</p> <p>To create a virtual environment for development, run the following in your shell:</p> <pre><code>pip install poetry\npoetry shell\npoetry install --with dev\n</code></pre> <p>Simply use <code>exit</code> to deactivate the environment. The next time you call <code>poetry shell</code> the environment will already be setup and ready to go.</p>"},{"location":"CONTRIBUTING/#development-workflow","title":"Development Workflow","text":"<ol> <li> <p>Search through existing GitHub Issues to see if what you want to work on has already been added.</p> <ul> <li>If not, please create a new issue. This will help to reduce duplicated work.</li> </ul> </li> <li> <p>For first-time contributors, visit https://github.com/mirascope/mirascope and \"Fork\" the repository (see the button in the top right corner).</p> <ul> <li> <p>You'll need to set up SSH authentication.</p> </li> <li> <p>Clone the forked project and point it to the main project:</p> </li> </ul> <pre><code>git clone https://github.com/&lt;your-username&gt;/mirascope.git\ngit remote add upstream https://github.com/Mirascope/mirascope.git\n</code></pre> </li> <li> <p>Development.</p> <ul> <li>Make sure you are in sync with the main repo:</li> </ul> <pre><code>git checkout dev\ngit pull upstream dev\n</code></pre> <ul> <li>Create a <code>git</code> feature branch with a meaningful name where you will add your contributions.</li> </ul> <pre><code>git checkout -b meaningful-branch-name\n</code></pre> <ul> <li>Start coding! commit your changes locally as you work:</li> </ul> <pre><code>git add mirascope/modified_file.py tests/test_modified_file.py\ngit commit -m \"feat: specific description of changes contained in commit\"\n</code></pre> <ul> <li>Format your code!</li> </ul> <pre><code>poetry run ruff format .\n</code></pre> <ul> <li>Lint and test your code! From the base directory, run:</li> </ul> <pre><code>poetry run ruff check .\npoetry run mypy .\n</code></pre> </li> <li> <p>Contributions are submitted through GitHub Pull Requests</p> <ul> <li>When you are ready to submit your contribution for review, push your branch:</li> </ul> <pre><code>git push origin meaningful-branch-name\n</code></pre> <ul> <li> <p>Open the printed URL to open a PR. Make sure to fill in a detailed title and description. Submit your PR for review.</p> </li> <li> <p>Link the issue you selected or created under \"Development\"</p> </li> <li> <p>We will review your contribution and add any comments to the PR. Commit any updates you make in response to comments and push them to the branch (they will be automatically included in the PR)</p> </li> </ul> </li> </ol>"},{"location":"CONTRIBUTING/#pull-requests","title":"Pull Requests","text":"<p>Please conform to the Conventional Commits specification for all PR titles and commits.</p>"},{"location":"CONTRIBUTING/#testing","title":"Testing","text":"<p>All changes to the codebase must be properly unit tested. If a change requires updating an existing unit test, make sure to think through if the change is breaking.</p> <p>We use <code>pytest</code> as our testing framework. If you haven't worked with it before, take a look at their docs.</p>"},{"location":"CONTRIBUTING/#formatting-and-linting","title":"Formatting and Linting","text":"<p>In an effort to keep the codebase clean and easy to work with, we use <code>ruff</code> for formatting and both <code>ruff</code> and <code>mypy</code> for linting. Before sending any PR for review, make sure to run both <code>ruff</code> and <code>mypy</code>.</p> <p>If you are using VS Code, then install the extensions in <code>.vscode/extensions.json</code> and the workspace settings should automatically run <code>ruff</code> formatting on save and show <code>ruff</code> and <code>mypy</code> errors.</p>"},{"location":"HELP/","title":"How to help Mirascope","text":""},{"location":"HELP/#star-mirascope-on-github","title":"Star Mirascope on GitHub","text":"<p>\u2b50\ufe0f You can \"star\" Mirascope on GitHub \u2b50\ufe0f</p>"},{"location":"HELP/#connect-with-the-authors","title":"Connect with the authors","text":"<ul> <li> <p>Follow us on GitHub</p> <ul> <li>See other related Open Source projects that might help you with machine learning</li> </ul> </li> <li> <p>Follow William Bakst on Twitter/X</p> <ul> <li>Tell me how you use mirascope</li> <li>Hear about new announcements or releases</li> </ul> </li> <li> <p>Connect with William Bakst on LinkedIn</p> <ul> <li>Give me any feedback or suggestions about what we're building</li> </ul> </li> </ul>"},{"location":"HELP/#post-about-mirascope","title":"Post about Mirascope","text":"<ul> <li> <p>Twitter, Reddit, Hackernews, LinkedIn, and others.</p> </li> <li> <p>We love to hear about how Mirascope has helped you and how you are using it.</p> </li> </ul>"},{"location":"HELP/#help-others","title":"Help Others","text":"<p>We are a kind and welcoming community that encourages you to help others with their questions on GitHub Issues / Discussions.</p> <ul> <li>Guide for asking questions<ul> <li>First, search through issues and discussions to see if others have faced similar issues</li> <li>Be as specific as possible, add minimal reproducible example</li> <li>List out things you have tried, errors, etc</li> <li>Close the issue if your question has been successfully answered</li> </ul> </li> <li>Guide for answering questions<ul> <li>Understand the question, ask clarifying questions</li> <li>If there is sample code, reproduce the issue with code given by original poster</li> <li>Give them solution or possibly an alternative that might be better than what original poster is trying to do</li> <li>Ask original poster to close the issue</li> </ul> </li> </ul>"},{"location":"HELP/#review-pull-requests","title":"Review Pull Requests","text":"<p>You are encouraged to review any pull requests. Here is a guideline on how to review a pull request:</p> <ul> <li>Understand the problem the pull request is trying to solve</li> <li>Ask clarification questions to determine whether the pull request belongs in the package</li> <li>Check the code, run it locally, see if it solves the problem described by the pull request</li> <li>Add a comment with screenshots or accompanying code to verify that you have tested it</li> <li>Check for tests<ul> <li>Request the original poster to add tests if they do not exist</li> <li>Check that tests fail before the PR and succeed after</li> </ul> </li> <li>This will greatly speed up the review process for a PR and will ultimately make Mirascope a better package</li> </ul>"},{"location":"api/enums/","title":"enums","text":"<p>Enum Classes for mirascope.</p>"},{"location":"api/enums/#mirascope.enums.MirascopeCommand","title":"<code>MirascopeCommand</code>","text":"<p>             Bases: <code>_Enum</code></p> <p>CLI commands to be executed.</p> Source code in <code>mirascope/enums.py</code> <pre><code>class MirascopeCommand(_Enum):\n    \"\"\"CLI commands to be executed.\"\"\"\n\n    ADD = \"add\"\n    USE = \"use\"\n    STATUS = \"status\"\n    INIT = \"init\"\n</code></pre>"},{"location":"api/prompts/","title":"prompts","text":"<p>A class for better prompting.</p>"},{"location":"api/prompts/#mirascope.prompts.Prompt","title":"<code>Prompt</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>A Pydantic model for prompts.</p> Source code in <code>mirascope/prompts.py</code> <pre><code>class Prompt(BaseModel):\n    \"\"\"A Pydantic model for prompts.\"\"\"\n\n    @classmethod\n    def template(cls) -&gt; str:\n        \"\"\"Custom parsing functionality for docstring prompt.\n\n        This function is the first step in formatting the prompt template docstring.\n        For the default `Prompt`, this function dedents the docstring and replaces all\n        repeated sequences of newlines with one fewer newline character. This enables\n        writing blocks of text instead of really long single lines. To include any\n        number of newline characters, simply include one extra.\n\n        Raises:\n            ValueError: If the class docstring is empty.\n        \"\"\"\n        if cls.__doc__ is None:\n            raise ValueError(\"`Prompt` must have a prompt template docstring.\")\n\n        return re.sub(\n            \"(\\n+)\",\n            lambda x: x.group(0)[:-1] if len(x.group(0)) &gt; 1 else \" \",\n            dedent(cls.__doc__).strip(\"\\n\"),\n        )\n\n    def __str__(self) -&gt; str:\n        \"\"\"Returns the docstring prompt template formatted with template variables.\"\"\"\n        template = self.template()\n        template_vars = [\n            var for _, var, _, _ in Formatter().parse(template) if var is not None\n        ]\n        return template.format(**{var: getattr(self, var) for var in template_vars})\n\n    def save(self, filepath: str):\n        \"\"\"Saves the prompt to the given filepath.\"\"\"\n        with open(filepath, \"wb\") as f:\n            pickle.dump(self, f)\n\n    @classmethod\n    def load(cls, filepath: str) -&gt; Prompt:\n        \"\"\"Loads the prompt from the given filepath.\"\"\"\n        with open(filepath, \"rb\") as f:\n            return pickle.load(f)\n</code></pre>"},{"location":"api/prompts/#mirascope.prompts.Prompt.__str__","title":"<code>__str__()</code>","text":"<p>Returns the docstring prompt template formatted with template variables.</p> Source code in <code>mirascope/prompts.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Returns the docstring prompt template formatted with template variables.\"\"\"\n    template = self.template()\n    template_vars = [\n        var for _, var, _, _ in Formatter().parse(template) if var is not None\n    ]\n    return template.format(**{var: getattr(self, var) for var in template_vars})\n</code></pre>"},{"location":"api/prompts/#mirascope.prompts.Prompt.load","title":"<code>load(filepath)</code>  <code>classmethod</code>","text":"<p>Loads the prompt from the given filepath.</p> Source code in <code>mirascope/prompts.py</code> <pre><code>@classmethod\ndef load(cls, filepath: str) -&gt; Prompt:\n    \"\"\"Loads the prompt from the given filepath.\"\"\"\n    with open(filepath, \"rb\") as f:\n        return pickle.load(f)\n</code></pre>"},{"location":"api/prompts/#mirascope.prompts.Prompt.save","title":"<code>save(filepath)</code>","text":"<p>Saves the prompt to the given filepath.</p> Source code in <code>mirascope/prompts.py</code> <pre><code>def save(self, filepath: str):\n    \"\"\"Saves the prompt to the given filepath.\"\"\"\n    with open(filepath, \"wb\") as f:\n        pickle.dump(self, f)\n</code></pre>"},{"location":"api/prompts/#mirascope.prompts.Prompt.template","title":"<code>template()</code>  <code>classmethod</code>","text":"<p>Custom parsing functionality for docstring prompt.</p> <p>This function is the first step in formatting the prompt template docstring. For the default <code>Prompt</code>, this function dedents the docstring and replaces all repeated sequences of newlines with one fewer newline character. This enables writing blocks of text instead of really long single lines. To include any number of newline characters, simply include one extra.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the class docstring is empty.</p> Source code in <code>mirascope/prompts.py</code> <pre><code>@classmethod\ndef template(cls) -&gt; str:\n    \"\"\"Custom parsing functionality for docstring prompt.\n\n    This function is the first step in formatting the prompt template docstring.\n    For the default `Prompt`, this function dedents the docstring and replaces all\n    repeated sequences of newlines with one fewer newline character. This enables\n    writing blocks of text instead of really long single lines. To include any\n    number of newline characters, simply include one extra.\n\n    Raises:\n        ValueError: If the class docstring is empty.\n    \"\"\"\n    if cls.__doc__ is None:\n        raise ValueError(\"`Prompt` must have a prompt template docstring.\")\n\n    return re.sub(\n        \"(\\n+)\",\n        lambda x: x.group(0)[:-1] if len(x.group(0)) &gt; 1 else \" \",\n        dedent(cls.__doc__).strip(\"\\n\"),\n    )\n</code></pre>"},{"location":"api/prompts/#mirascope.prompts.messages","title":"<code>messages(cls)</code>","text":"<p>A decorator for adding a <code>messages</code> class attribute to a <code>Prompt</code>.</p> <p>Adding this decorator to a <code>Prompt</code> adds a <code>messages</code> class attribute that parses the docstring as a list of messages. Each message is a tuple containing the role and the content. The docstring should have the following format:</p> <pre><code>&lt;role&gt;:\n&lt;content&gt;\n</code></pre> <p>For example, you might want to first include a system prompt followed by a user prompt, which you can structure as follows:</p> <pre><code>SYSTEM:\nThis would be the system message content.\n\nUSER:\nThis would be the user message content.\n</code></pre> <p>Returns:</p> Type Description <code>Type[T]</code> <p>A list of tuples <code>(role, content)</code> parsed from the docstring.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the docstring is empty.</p> Source code in <code>mirascope/prompts.py</code> <pre><code>def messages(cls: Type[T]) -&gt; Type[T]:\n    \"\"\"A decorator for adding a `messages` class attribute to a `Prompt`.\n\n    Adding this decorator to a `Prompt` adds a `messages` class attribute\n    that parses the docstring as a list of messages. Each message is a tuple containing\n    the role and the content. The docstring should have the following format:\n\n        &lt;role&gt;:\n        &lt;content&gt;\n\n    For example, you might want to first include a system prompt followed by a user\n    prompt, which you can structure as follows:\n\n        SYSTEM:\n        This would be the system message content.\n\n        USER:\n        This would be the user message content.\n\n    Returns:\n        A list of tuples `(role, content)` parsed from the docstring.\n\n    Raises:\n        ValueError: If the docstring is empty.\n    \"\"\"\n\n    def messages_fn(self) -&gt; list[tuple[str, str]]:\n        \"\"\"Returns the docstring as a list of messages.\"\"\"\n        if self.__doc__ is None:\n            raise ValueError(\"`Prompt` must have a prompt template docstring.\")\n\n        return [\n            (match.group(1).lower(), match.group(2))\n            for match in re.finditer(\n                r\"(SYSTEM|USER|ASSISTANT): ((.|\\n)+?)(?=\\n(SYSTEM|USER|ASSISTANT):|\\Z)\",\n                str(self),\n            )\n        ]\n\n    setattr(cls, \"messages\", property(messages_fn))\n    return cls\n</code></pre>"},{"location":"api/chat/","title":"chat","text":"<p>A module for interacting with Chat APIs.</p>"},{"location":"api/chat/models/","title":"chat.models","text":"<p>Classes for interactings with LLMs through Chat APIs.</p>"},{"location":"api/chat/models/#mirascope.chat.models.OpenAIChat","title":"<code>OpenAIChat</code>","text":"<p>A convenience wrapper for the OpenAI Chat client.</p> Source code in <code>mirascope/chat/models.py</code> <pre><code>class OpenAIChat:\n    \"\"\"A convenience wrapper for the OpenAI Chat client.\"\"\"\n\n    def __init__(self, model: str = \"gpt-3.5-turbo\", api_key: Optional[str] = None):\n        \"\"\"Initializes an instance of `OpenAIChat.\"\"\"\n        self.client = OpenAI(api_key=api_key)\n        self.model = model\n\n    def create(self, prompt: Prompt, **kwargs) -&gt; OpenAIChatCompletion:\n        \"\"\"Makes a call to the model using `prompt`.\n\n        Args:\n            prompt: The `Prompt` to use for the call.\n            stream: Whether or not to stream the response.\n            **kwargs: Additional keyword arguments to pass to the API call. You can\n                find available keyword arguments here:\n                https://platform.openai.com/docs/api-reference/chat/create\n\n        Returns:\n            A `OpenAIChatCompletion` instance.\n\n        Raises:\n            Re-raises any exceptions thrown by the openai chat completions create call.\n        \"\"\"\n        try:\n            return OpenAIChatCompletion(\n                completion=self.client.chat.completions.create(\n                    model=self.model,\n                    messages=get_messages(prompt),\n                    stream=False,\n                    **kwargs,\n                )\n            )\n        except:\n            raise\n\n    def stream(\n        self, prompt: Prompt, **kwargs\n    ) -&gt; Generator[OpenAIChatCompletionChunk, None, None]:\n        \"\"\"Streams the response for a call to the model using `prompt`.\n\n        Args:\n            prompt: The `Prompt` to use for the call.\n            **kwargs: Additional keyword arguments to pass to the API call. You can\n                find available keyword arguments here:\n                https://platform.openai.com/docs/api-reference/chat/create\n\n        Yields:\n            A `OpenAIChatCompletionChunk` for each chunk of the response.\n\n        Raises:\n            Re-raises any exceptions thrown by the openai chat completions create call.\n        \"\"\"\n        completion_stream = self.client.chat.completions.create(\n            model=self.model,\n            messages=get_messages(prompt),\n            stream=True,\n            **kwargs,\n        )\n        for chunk in completion_stream:\n            yield OpenAIChatCompletionChunk(chunk=chunk)\n</code></pre>"},{"location":"api/chat/models/#mirascope.chat.models.OpenAIChat.__init__","title":"<code>__init__(model='gpt-3.5-turbo', api_key=None)</code>","text":"<p>Initializes an instance of `OpenAIChat.</p> Source code in <code>mirascope/chat/models.py</code> <pre><code>def __init__(self, model: str = \"gpt-3.5-turbo\", api_key: Optional[str] = None):\n    \"\"\"Initializes an instance of `OpenAIChat.\"\"\"\n    self.client = OpenAI(api_key=api_key)\n    self.model = model\n</code></pre>"},{"location":"api/chat/models/#mirascope.chat.models.OpenAIChat.create","title":"<code>create(prompt, **kwargs)</code>","text":"<p>Makes a call to the model using <code>prompt</code>.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>Prompt</code> <p>The <code>Prompt</code> to use for the call.</p> required <code>stream</code> <p>Whether or not to stream the response.</p> required <code>**kwargs</code> <p>Additional keyword arguments to pass to the API call. You can find available keyword arguments here: https://platform.openai.com/docs/api-reference/chat/create</p> <code>{}</code> <p>Returns:</p> Type Description <code>OpenAIChatCompletion</code> <p>A <code>OpenAIChatCompletion</code> instance.</p> Source code in <code>mirascope/chat/models.py</code> <pre><code>def create(self, prompt: Prompt, **kwargs) -&gt; OpenAIChatCompletion:\n    \"\"\"Makes a call to the model using `prompt`.\n\n    Args:\n        prompt: The `Prompt` to use for the call.\n        stream: Whether or not to stream the response.\n        **kwargs: Additional keyword arguments to pass to the API call. You can\n            find available keyword arguments here:\n            https://platform.openai.com/docs/api-reference/chat/create\n\n    Returns:\n        A `OpenAIChatCompletion` instance.\n\n    Raises:\n        Re-raises any exceptions thrown by the openai chat completions create call.\n    \"\"\"\n    try:\n        return OpenAIChatCompletion(\n            completion=self.client.chat.completions.create(\n                model=self.model,\n                messages=get_messages(prompt),\n                stream=False,\n                **kwargs,\n            )\n        )\n    except:\n        raise\n</code></pre>"},{"location":"api/chat/models/#mirascope.chat.models.OpenAIChat.stream","title":"<code>stream(prompt, **kwargs)</code>","text":"<p>Streams the response for a call to the model using <code>prompt</code>.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>Prompt</code> <p>The <code>Prompt</code> to use for the call.</p> required <code>**kwargs</code> <p>Additional keyword arguments to pass to the API call. You can find available keyword arguments here: https://platform.openai.com/docs/api-reference/chat/create</p> <code>{}</code> <p>Yields:</p> Type Description <code>OpenAIChatCompletionChunk</code> <p>A <code>OpenAIChatCompletionChunk</code> for each chunk of the response.</p> Source code in <code>mirascope/chat/models.py</code> <pre><code>def stream(\n    self, prompt: Prompt, **kwargs\n) -&gt; Generator[OpenAIChatCompletionChunk, None, None]:\n    \"\"\"Streams the response for a call to the model using `prompt`.\n\n    Args:\n        prompt: The `Prompt` to use for the call.\n        **kwargs: Additional keyword arguments to pass to the API call. You can\n            find available keyword arguments here:\n            https://platform.openai.com/docs/api-reference/chat/create\n\n    Yields:\n        A `OpenAIChatCompletionChunk` for each chunk of the response.\n\n    Raises:\n        Re-raises any exceptions thrown by the openai chat completions create call.\n    \"\"\"\n    completion_stream = self.client.chat.completions.create(\n        model=self.model,\n        messages=get_messages(prompt),\n        stream=True,\n        **kwargs,\n    )\n    for chunk in completion_stream:\n        yield OpenAIChatCompletionChunk(chunk=chunk)\n</code></pre>"},{"location":"api/chat/types/","title":"chat.types","text":"<p>Classes for responses when interacting with a Chat API.</p>"},{"location":"api/chat/types/#mirascope.chat.types.OpenAIChatCompletion","title":"<code>OpenAIChatCompletion</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Convenience wrapper around chat completions.</p> Source code in <code>mirascope/chat/types.py</code> <pre><code>class OpenAIChatCompletion(BaseModel):\n    \"\"\"Convenience wrapper around chat completions.\"\"\"\n\n    completion: ChatCompletion\n\n    @property\n    def choices(self) -&gt; list[Choice]:\n        \"\"\"Returns the array of chat completion choices.\"\"\"\n        return self.completion.choices\n\n    @property\n    def choice(self) -&gt; Choice:\n        \"\"\"Returns the 0th choice.\"\"\"\n        return self.completion.choices[0]\n\n    @property\n    def message(self) -&gt; ChatCompletionMessage:\n        \"\"\"Returns the message of the chat completion for the 0th choice.\"\"\"\n        return self.completion.choices[0].message\n\n    @property\n    def content(self) -&gt; Optional[str]:\n        \"\"\"Returns the content of the chat completion for the 0th choice.\"\"\"\n        return self.completion.choices[0].message.content\n\n    def __str__(self):\n        \"\"\"Returns the contained string content for the 0th choice.\"\"\"\n        return self.content\n</code></pre>"},{"location":"api/chat/types/#mirascope.chat.types.OpenAIChatCompletion.choice","title":"<code>choice: Choice</code>  <code>property</code>","text":"<p>Returns the 0th choice.</p>"},{"location":"api/chat/types/#mirascope.chat.types.OpenAIChatCompletion.choices","title":"<code>choices: list[Choice]</code>  <code>property</code>","text":"<p>Returns the array of chat completion choices.</p>"},{"location":"api/chat/types/#mirascope.chat.types.OpenAIChatCompletion.content","title":"<code>content: Optional[str]</code>  <code>property</code>","text":"<p>Returns the content of the chat completion for the 0th choice.</p>"},{"location":"api/chat/types/#mirascope.chat.types.OpenAIChatCompletion.message","title":"<code>message: ChatCompletionMessage</code>  <code>property</code>","text":"<p>Returns the message of the chat completion for the 0th choice.</p>"},{"location":"api/chat/types/#mirascope.chat.types.OpenAIChatCompletion.__str__","title":"<code>__str__()</code>","text":"<p>Returns the contained string content for the 0th choice.</p> Source code in <code>mirascope/chat/types.py</code> <pre><code>def __str__(self):\n    \"\"\"Returns the contained string content for the 0th choice.\"\"\"\n    return self.content\n</code></pre>"},{"location":"api/chat/types/#mirascope.chat.types.OpenAIChatCompletionChunk","title":"<code>OpenAIChatCompletionChunk</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Convenience wrapper around chat completion streaming chunks.</p> Source code in <code>mirascope/chat/types.py</code> <pre><code>class OpenAIChatCompletionChunk(BaseModel):\n    \"\"\"Convenience wrapper around chat completion streaming chunks.\"\"\"\n\n    chunk: ChatCompletionChunk\n\n    @property\n    def choices(self) -&gt; list[ChunkChoice]:\n        \"\"\"Returns the array of chat completion choices.\"\"\"\n        return self.chunk.choices\n\n    @property\n    def choice(self) -&gt; ChunkChoice:\n        \"\"\"Returns the 0th choice.\"\"\"\n        return self.chunk.choices[0]\n\n    @property\n    def delta(self) -&gt; ChoiceDelta:\n        \"\"\"Returns the delta for the 0th choice.\"\"\"\n        return self.choices[0].delta\n\n    @property\n    def content(self) -&gt; Optional[str]:\n        \"\"\"Returns the content for the 0th choice delta.\"\"\"\n        return self.delta.content\n\n    def __str__(self) -&gt; str:\n        \"\"\"Returns the chunk content for the 0th choice.\"\"\"\n        return self.content if self.content is not None else \"\"\n</code></pre>"},{"location":"api/chat/types/#mirascope.chat.types.OpenAIChatCompletionChunk.choice","title":"<code>choice: ChunkChoice</code>  <code>property</code>","text":"<p>Returns the 0th choice.</p>"},{"location":"api/chat/types/#mirascope.chat.types.OpenAIChatCompletionChunk.choices","title":"<code>choices: list[ChunkChoice]</code>  <code>property</code>","text":"<p>Returns the array of chat completion choices.</p>"},{"location":"api/chat/types/#mirascope.chat.types.OpenAIChatCompletionChunk.content","title":"<code>content: Optional[str]</code>  <code>property</code>","text":"<p>Returns the content for the 0th choice delta.</p>"},{"location":"api/chat/types/#mirascope.chat.types.OpenAIChatCompletionChunk.delta","title":"<code>delta: ChoiceDelta</code>  <code>property</code>","text":"<p>Returns the delta for the 0th choice.</p>"},{"location":"api/chat/types/#mirascope.chat.types.OpenAIChatCompletionChunk.__str__","title":"<code>__str__()</code>","text":"<p>Returns the chunk content for the 0th choice.</p> Source code in <code>mirascope/chat/types.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Returns the chunk content for the 0th choice.\"\"\"\n    return self.content if self.content is not None else \"\"\n</code></pre>"},{"location":"api/chat/utils/","title":"chat.utils","text":"<p>Utility functions for mirascope chat.</p>"},{"location":"api/chat/utils/#mirascope.chat.utils.get_messages","title":"<code>get_messages(prompt)</code>","text":"<p>Returns a list of messages parsed from the prompt.</p> Source code in <code>mirascope/chat/utils.py</code> <pre><code>def get_messages(\n    prompt: Prompt,\n) -&gt; list[ChatCompletionMessageParam]:\n    \"\"\"Returns a list of messages parsed from the prompt.\"\"\"\n    if hasattr(prompt, \"messages\"):\n        return [{\"role\": role, \"content\": content} for role, content in prompt.messages]\n    return [{\"role\": \"user\", \"content\": str(prompt)}]\n</code></pre>"},{"location":"api/cli/","title":"cli","text":"<p>This module contains all functionality related to the Mirascope CLI.</p>"},{"location":"api/cli/cli/","title":"cli.cli","text":"<p>The Mirascope CLI prompt management tool.</p> <p>Typical usage example:</p> <pre><code>Initialize the environment:\n    $ mirascope init mirascope\n\nCreate a prompt in the prompts directory:\n    prompts/my_prompt.py\n\nAdd the prompt to create a version:\n    $ mirascope add my_prompt\n\nIterate on the prompt in the prompts directory:\n\nCheck the status of the prompt:\n    $ mirascope status my_prompt\n\nAdd the prompt to create a new version:\n    $ mirascope add my_prompt\n\nSwitch between prompts:\n    $ mirascope use my_prompt 0001\n</code></pre>"},{"location":"api/cli/cli/#mirascope.cli.cli.main","title":"<code>main()</code>","text":"<p>The runner for Mirascope CLI tool</p> Source code in <code>mirascope/cli/cli.py</code> <pre><code>def main():\n    \"\"\"The runner for Mirascope CLI tool\"\"\"\n    parser = argparse.ArgumentParser(description=\"Mirascope CLI Tool\")\n\n    subparsers = parser.add_subparsers(dest=\"command\")\n    subparsers.required = True\n\n    # Adding 'add' command\n    parser_add = subparsers.add_parser(\"add\", help=\"Add an item\")\n    parser_add.add_argument(\"prompt\", help=\"File to add, without extension (.py)\")\n    parser_add.set_defaults(func=add)\n\n    # Adding 'status' command\n    parser_status = subparsers.add_parser(\"status\", help=\"Check status of prompts\")\n    parser_status.add_argument(\n        \"directory_name\", nargs=\"?\", default=None, help=\"Prompt to check status on\"\n    )\n    parser_status.set_defaults(func=status)\n\n    # Adding 'use' command\n    parser_use = subparsers.add_parser(\"use\", help=\"Use a prompt\")\n    parser_use.add_argument(\"directory_name\", help=\"Prompt directory to use\")\n    parser_use.add_argument(\"version\", help=\"Version of prompt to use\")\n    parser_use.set_defaults(func=use)\n\n    # Adding 'init' command\n    parser_init = subparsers.add_parser(\"init\", help=\"Initialize mirascope project\")\n    parser_init.add_argument(\n        \"--mirascope_location\", default=\"mirascope\", help=\"Main mirascope directory\"\n    )\n    parser_init.add_argument(\n        \"--prompts_location\", default=\"prompts\", help=\"Location of prompts directory\"\n    )\n    parser_init.set_defaults(func=init)\n\n    args = parser.parse_args()\n    args.func(args)\n</code></pre>"},{"location":"api/cli/commands/","title":"cli.commands","text":"<p>Commands for Mirascope CLI.</p> <p>This module contains the commands for the Mirascope CLI. The commands are add, status,  use, and init. See the documentation for each command for more information.</p>"},{"location":"api/cli/commands/#mirascope.cli.commands.add","title":"<code>add(args)</code>","text":"<p>Adds the given prompt to the specified version directory.</p> <p>The contents of the prompt in the user's prompts directory are copied to the version directory with the next revision number, and the version file is updated with the new revision.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <p>The command line arguments for the <code>add</code> command, containing: - <code>prompt</code>: The name of the prompt to add.</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file is not found in the specified prompts directory.</p> Source code in <code>mirascope/cli/commands.py</code> <pre><code>def add(args) -&gt; None:\n    \"\"\"Adds the given prompt to the specified version directory.\n\n    The contents of the prompt in the user's prompts directory are copied to the version\n    directory with the next revision number, and the version file is updated with the\n    new revision.\n\n    Args:\n        args: The command line arguments for the `add` command, containing:\n            - `prompt`: The name of the prompt to add.\n\n    Raises:\n        FileNotFoundError: If the file is not found in the specified prompts directory.\n    \"\"\"\n    mirascope_settings = get_user_mirascope_settings()\n    version_directory_path = mirascope_settings.versions_location\n    prompt_directory_path = mirascope_settings.prompts_location\n    version_file_name = mirascope_settings.version_file_name\n    directory_name: str = args.prompt\n\n    # Check status before continuing\n    used_prompt_path = check_status(mirascope_settings, directory_name)\n    if not used_prompt_path:\n        print(\"No changes detected.\")\n        return\n    class_directory = os.path.join(version_directory_path, directory_name)\n\n    # Create version directory if it doesn't exist\n    if not os.path.exists(class_directory):\n        os.makedirs(class_directory)\n    version_file_path = os.path.join(class_directory, version_file_name)\n    versions = get_prompt_versions(version_file_path)\n\n    # Open user's prompt file\n    with open(\n        f\"{prompt_directory_path}/{directory_name}.py\", \"r+\", encoding=\"utf-8\"\n    ) as file:\n        # Increment revision id\n        if versions.latest_revision is None:\n            # first revision\n            revision_id = \"0001\"\n        else:\n            # default branch with incrementation\n            latest_revision_id = versions.latest_revision\n            revision_id = f\"{int(latest_revision_id)+1:04}\"\n        # Create revision file\n        with open(\n            f\"{class_directory}/{revision_id}_{directory_name}.py\",\n            \"w+\",\n            encoding=\"utf-8\",\n        ) as file2:\n            custom_variables = {\n                \"prev_revision_id\": versions.current_revision,\n                \"revision_id\": revision_id,\n            }\n            file2.write(\n                write_prompt_to_template(\n                    file.read(), MirascopeCommand.ADD, custom_variables\n                )\n            )\n            keys_to_update = {\n                CURRENT_REVISION_KEY: revision_id,\n                LATEST_REVISION_KEY: revision_id,\n            }\n            update_version_text_file(version_file_path, keys_to_update)\n\n    print(\n        \"Adding \"\n        f\"{version_directory_path}/{directory_name}/{revision_id}_{directory_name}.py\"\n    )\n</code></pre>"},{"location":"api/cli/commands/#mirascope.cli.commands.init","title":"<code>init(args)</code>","text":"<p>Initializes the mirascope project.</p> <p>Creates the project structure and files needed for mirascope to work.</p> <p>Initial project structure: | |-- mirascope.ini |-- mirascope |   |-- prompt_template.j2 |   |-- versions/ |   |   |-- / |   |   |   |-- version.txt |   |   |   |-- _.py |-- prompts/ <p>Parameters:</p> Name Type Description Default <code>args</code> <p>The command line arguments for the <code>init</code> command, containing: - <code>--mirascope_location</code>: The root mirascope directory to create. - <code>--prompts_location</code>: The user's prompts directory.</p> required Source code in <code>mirascope/cli/commands.py</code> <pre><code>def init(args) -&gt; None:\n    \"\"\"Initializes the mirascope project.\n\n    Creates the project structure and files needed for mirascope to work.\n\n    Initial project structure:\n    |\n    |-- mirascope.ini\n    |-- mirascope\n    |   |-- prompt_template.j2\n    |   |-- versions/\n    |   |   |-- &lt;directory_name&gt;/\n    |   |   |   |-- version.txt\n    |   |   |   |-- &lt;revision_id&gt;_&lt;directory_name&gt;.py\n    |-- prompts/\n\n    Args:\n        args: The command line arguments for the `init` command, containing:\n            - `--mirascope_location`: The root mirascope directory to create.\n            - `--prompts_location`: The user's prompts directory.\n    \"\"\"\n    destination_dir = Path.cwd()\n    mirascope_location = args.mirascope_location\n    prompts_location = args.prompts_location\n    versions_directory = os.path.join(mirascope_location, \"versions\")\n    os.makedirs(versions_directory, exist_ok=True)\n    print(f\"Creating {destination_dir}/{versions_directory}\")\n    os.makedirs(prompts_location, exist_ok=True)\n    print(f\"Creating {destination_dir}/{prompts_location}\")\n    prompts_init_file: Path = Path(f\"{destination_dir}/{prompts_location}/__init__.py\")\n    if not prompts_init_file.is_file():\n        prompts_init_file.touch()\n        print(f\"Creating {prompts_init_file}\")\n    # Create the 'mirascope.ini' file in the current directory with some default values\n    ini_settings = MirascopeSettings(\n        mirascope_location=mirascope_location,\n        versions_location=\"versions\",\n        prompts_location=prompts_location,\n        version_file_name=\"version.txt\",\n    )\n\n    # Get templates from the mirascope.cli.generic package\n    generic_file_path = files(\"mirascope.cli.generic\")\n    ini_path = generic_file_path.joinpath(\"mirascope.ini.j2\")\n    with open(str(ini_path), \"r\", encoding=\"utf-8\") as file:\n        template = Template(file.read())\n        rendered_content = template.render(ini_settings.model_dump())\n        destination_file_path = destination_dir / \"mirascope.ini\"\n        with open(destination_file_path, \"w\", encoding=\"utf-8\") as destination_file:\n            destination_file.write(rendered_content)\n            print(f\"Creating {destination_file_path}\")\n\n    # Create the 'prompt_template.j2' file in the mirascope directory specified by user\n    prompt_template_path = generic_file_path.joinpath(\"prompt_template.j2\")\n    with open(str(prompt_template_path), \"r\", encoding=\"utf-8\") as file:\n        content = file.read()\n    template_path = os.path.join(mirascope_location, \"prompt_template.j2\")\n    with open(template_path, \"w\", encoding=\"utf-8\") as file:\n        file.write(content)\n        print(f\"Creating {destination_dir}/{template_path}\")\n\n    print(\"Initialization complete.\")\n</code></pre>"},{"location":"api/cli/commands/#mirascope.cli.commands.status","title":"<code>status(args)</code>","text":"<p>Checks the status of the current prompt or prompts.</p> <p>If a prompt is specified, the status of that prompt is checked. Otherwise, the status of all promps are checked. If a prompt has changed, the path to the prompt is printed.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <p>The command line arguments for the <code>status</code> command, containing: - <code>directory_name</code>: (Optional) The name of the directory to check status on.</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file is not found in the specified prompts directory.</p> Source code in <code>mirascope/cli/commands.py</code> <pre><code>def status(args) -&gt; None:\n    \"\"\"Checks the status of the current prompt or prompts.\n\n    If a prompt is specified, the status of that prompt is checked. Otherwise, the\n    status of all promps are checked. If a prompt has changed, the path to the prompt\n    is printed.\n\n    Args:\n        args: The command line arguments for the `status` command, containing:\n            - `directory_name`: (Optional) The name of the directory to check status on.\n\n    Raises:\n        FileNotFoundError: If the file is not found in the specified prompts directory.\n    \"\"\"\n    mirascope_settings = get_user_mirascope_settings()\n    version_directory_path = mirascope_settings.versions_location\n    directory_name: str = args.directory_name\n\n    # If a prompt is specified, check the status of that prompt\n    if directory_name:\n        used_prompt_path = check_status(mirascope_settings, directory_name)\n        if used_prompt_path:\n            print(f\"Prompt {used_prompt_path} has changed.\")\n        else:\n            print(\"No changes detected.\")\n    else:  # Otherwise, check the status of all prompts\n        directores_changed: list[str] = []\n        for _, directories, _ in os.walk(version_directory_path):\n            for directory in directories:\n                used_prompt_path = check_status(mirascope_settings, directory)\n                if used_prompt_path:\n                    directores_changed.append(used_prompt_path)\n        if len(directores_changed) &gt; 0:\n            print(\"The following prompts have changed:\")\n            for prompt in directores_changed:\n                print(f\"\\t{prompt}\".expandtabs(4))\n        else:\n            print(\"No changes detected.\")\n</code></pre>"},{"location":"api/cli/commands/#mirascope.cli.commands.use","title":"<code>use(args)</code>","text":"<p>Uses the version and prompt specified by the user.</p> <p>The contents of the prompt in the versions directory are copied to the user's prompts directory, based on the version specified by the user. The version file is updated with the new revision.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <p>The command line arguments for the <code>use</code> command, containing: - <code>directory_name</code>: The name of the directory to use. - <code>version</code>: The version of the prompt to use.</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file is not found in the versions directory.</p> Source code in <code>mirascope/cli/commands.py</code> <pre><code>def use(args) -&gt; None:\n    \"\"\"Uses the version and prompt specified by the user.\n\n    The contents of the prompt in the versions directory are copied to the user's\n    prompts directory, based on the version specified by the user. The version file is\n    updated with the new revision.\n\n    Args:\n        args: The command line arguments for the `use` command, containing:\n            - `directory_name`: The name of the directory to use.\n            - `version`: The version of the prompt to use.\n\n    Raises:\n        FileNotFoundError: If the file is not found in the versions directory.\n    \"\"\"\n    directory_name = args.directory_name\n    version = args.version\n    mirascope_settings = get_user_mirascope_settings()\n    used_prompt_path = check_status(mirascope_settings, directory_name)\n\n    # Check status before continuing\n    if used_prompt_path:\n        print(\"Changes detected, please add or delete changes first.\")\n        print(f\"\\tmirascope add {directory_name}\".expandtabs(4))\n        return\n\n    version_directory_path = mirascope_settings.versions_location\n    prompt_directory_path = mirascope_settings.prompts_location\n    version_file_name = mirascope_settings.version_file_name\n    class_directory = os.path.join(version_directory_path, directory_name)\n    revision_file_path = find_prompt_path(class_directory, version)\n    version_file_path = os.path.join(class_directory, version_file_name)\n\n    # Open versioned prompt file\n    with open(revision_file_path, \"r\", encoding=\"utf-8\") as file:\n        content = file.read()\n    # Write to user's prompt file\n    prompt_file_name = os.path.join(prompt_directory_path, f\"{directory_name}.py\")\n    with open(prompt_file_name, \"w+\", encoding=\"utf-8\") as file2:\n        file2.write(write_prompt_to_template(content, MirascopeCommand.USE))\n\n    # Update version file with new current revision\n    keys_to_update = {\n        CURRENT_REVISION_KEY: version,\n    }\n    update_version_text_file(version_file_path, keys_to_update)\n\n    print(f\"Using {revision_file_path}\")\n</code></pre>"},{"location":"api/cli/constants/","title":"cli.constants","text":"<p>Constants for Mirascope CLI.</p>"},{"location":"api/cli/generic/","title":"cli.generic","text":"<p>This package contains generic templates that are used to initialize a mirascope project.</p>"},{"location":"api/cli/schemas/","title":"cli.schemas","text":"<p>Contains the schema for files created by the mirascope cli.</p>"},{"location":"api/cli/schemas/#mirascope.cli.schemas.MirascopeSettings","title":"<code>MirascopeSettings</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Model for the user's mirascope settings.</p> Source code in <code>mirascope/cli/schemas.py</code> <pre><code>class MirascopeSettings(BaseModel):\n    \"\"\"Model for the user's mirascope settings.\"\"\"\n\n    mirascope_location: str\n    versions_location: str\n    prompts_location: str\n    version_file_name: str\n\n    model_config = ConfigDict(extra=\"forbid\")\n</code></pre>"},{"location":"api/cli/schemas/#mirascope.cli.schemas.VersionTextFile","title":"<code>VersionTextFile</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Model for the version text file.</p> Source code in <code>mirascope/cli/schemas.py</code> <pre><code>class VersionTextFile(BaseModel):\n    \"\"\"Model for the version text file.\"\"\"\n\n    current_revision: Optional[str] = Field(default=None)\n    latest_revision: Optional[str] = Field(default=None)\n</code></pre>"},{"location":"api/cli/utils/","title":"cli.utils","text":"<p>Utility functions for the mirascope library.</p>"},{"location":"api/cli/utils/#mirascope.cli.utils.PromptAnalyzer","title":"<code>PromptAnalyzer</code>","text":"<p>             Bases: <code>NodeVisitor</code></p> <p>Utility class for analyzing a Mirascope prompt file.</p> Source code in <code>mirascope/cli/utils.py</code> <pre><code>class PromptAnalyzer(ast.NodeVisitor):\n    \"\"\"Utility class for analyzing a Mirascope prompt file.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initializes the PromptAnalyzer.\"\"\"\n        self.imports = []\n        self.from_imports = []\n        self.variables = {}\n        self.classes = []\n        self.decorators = []\n        self.comments = \"\"\n\n    def visit_Import(self, node):\n        \"\"\"Extracts imports from the given node.\"\"\"\n        for alias in node.names:\n            self.imports.append(alias.name)\n        self.generic_visit(node)\n\n    def visit_ImportFrom(self, node):\n        \"\"\"Extracts from imports from the given node.\"\"\"\n        for alias in node.names:\n            self.from_imports.append((node.module, alias.name))\n        self.generic_visit(node)\n\n    def visit_Assign(self, node):\n        \"\"\"Extracts variables from the given node.\"\"\"\n        target = node.targets[0]\n        if isinstance(target, ast.Name):\n            self.variables[target.id] = ast.unparse(node.value)\n        self.generic_visit(node)\n\n    def visit_ClassDef(self, node):\n        \"\"\"Extracts classes from the given node.\"\"\"\n        class_info = {\n            \"name\": node.name,\n            \"bases\": [ast.unparse(b) for b in node.bases],\n            \"body\": \"\",\n            \"decorators\": [ast.unparse(d) for d in node.decorator_list],\n            \"docstring\": None,\n        }\n\n        # Extract docstring if present\n        docstring = ast.get_docstring(node)\n        if docstring:\n            class_info[\"docstring\"] = '\"\"\"' + docstring + '\"\"\"'\n\n        # Handle the rest of the class body\n        body_nodes = [n for n in node.body if not isinstance(n, ast.Expr)]\n        class_info[\"body\"] = \"\\n\".join(ast.unparse(n) for n in body_nodes)\n\n        self.classes.append(class_info)\n\n    def visit_FunctionDef(self, node):\n        \"\"\"Extracts decorators from function definitions.\"\"\"\n        for decorator in node.decorator_list:\n            self.decorators.append(ast.unparse(decorator))\n        self.generic_visit(node)\n\n    def visit_Module(self, node):\n        \"\"\"Extracts comments from the given node.\"\"\"\n        comments = ast.get_docstring(node)\n        self.comments = \"\" if comments is None else comments\n        self.generic_visit(node)\n\n    def check_class_changed(self, other: \"PromptAnalyzer\") -&gt; bool:\n        \"\"\"Compares the classes of this file with the classes of another file.\"\"\"\n        self_classes = {c[\"name\"]: c for c in self.classes}\n        other_classes = {c[\"name\"]: c for c in other.classes}\n\n        all_class_names = set(self_classes.keys()) | set(other_classes.keys())\n\n        for name in all_class_names:\n            if name in self_classes and name in other_classes:\n                # Compare attributes of classes with the same name\n                class_diff = {\n                    attr: (self_classes[name][attr], other_classes[name][attr])\n                    for attr in self_classes[name]\n                    if self_classes[name][attr] != other_classes[name][attr]\n                }\n                if class_diff:\n                    return True\n            else:\n                return True\n\n        return False\n</code></pre>"},{"location":"api/cli/utils/#mirascope.cli.utils.PromptAnalyzer.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the PromptAnalyzer.</p> Source code in <code>mirascope/cli/utils.py</code> <pre><code>def __init__(self):\n    \"\"\"Initializes the PromptAnalyzer.\"\"\"\n    self.imports = []\n    self.from_imports = []\n    self.variables = {}\n    self.classes = []\n    self.decorators = []\n    self.comments = \"\"\n</code></pre>"},{"location":"api/cli/utils/#mirascope.cli.utils.PromptAnalyzer.check_class_changed","title":"<code>check_class_changed(other)</code>","text":"<p>Compares the classes of this file with the classes of another file.</p> Source code in <code>mirascope/cli/utils.py</code> <pre><code>def check_class_changed(self, other: \"PromptAnalyzer\") -&gt; bool:\n    \"\"\"Compares the classes of this file with the classes of another file.\"\"\"\n    self_classes = {c[\"name\"]: c for c in self.classes}\n    other_classes = {c[\"name\"]: c for c in other.classes}\n\n    all_class_names = set(self_classes.keys()) | set(other_classes.keys())\n\n    for name in all_class_names:\n        if name in self_classes and name in other_classes:\n            # Compare attributes of classes with the same name\n            class_diff = {\n                attr: (self_classes[name][attr], other_classes[name][attr])\n                for attr in self_classes[name]\n                if self_classes[name][attr] != other_classes[name][attr]\n            }\n            if class_diff:\n                return True\n        else:\n            return True\n\n    return False\n</code></pre>"},{"location":"api/cli/utils/#mirascope.cli.utils.PromptAnalyzer.visit_Assign","title":"<code>visit_Assign(node)</code>","text":"<p>Extracts variables from the given node.</p> Source code in <code>mirascope/cli/utils.py</code> <pre><code>def visit_Assign(self, node):\n    \"\"\"Extracts variables from the given node.\"\"\"\n    target = node.targets[0]\n    if isinstance(target, ast.Name):\n        self.variables[target.id] = ast.unparse(node.value)\n    self.generic_visit(node)\n</code></pre>"},{"location":"api/cli/utils/#mirascope.cli.utils.PromptAnalyzer.visit_ClassDef","title":"<code>visit_ClassDef(node)</code>","text":"<p>Extracts classes from the given node.</p> Source code in <code>mirascope/cli/utils.py</code> <pre><code>def visit_ClassDef(self, node):\n    \"\"\"Extracts classes from the given node.\"\"\"\n    class_info = {\n        \"name\": node.name,\n        \"bases\": [ast.unparse(b) for b in node.bases],\n        \"body\": \"\",\n        \"decorators\": [ast.unparse(d) for d in node.decorator_list],\n        \"docstring\": None,\n    }\n\n    # Extract docstring if present\n    docstring = ast.get_docstring(node)\n    if docstring:\n        class_info[\"docstring\"] = '\"\"\"' + docstring + '\"\"\"'\n\n    # Handle the rest of the class body\n    body_nodes = [n for n in node.body if not isinstance(n, ast.Expr)]\n    class_info[\"body\"] = \"\\n\".join(ast.unparse(n) for n in body_nodes)\n\n    self.classes.append(class_info)\n</code></pre>"},{"location":"api/cli/utils/#mirascope.cli.utils.PromptAnalyzer.visit_FunctionDef","title":"<code>visit_FunctionDef(node)</code>","text":"<p>Extracts decorators from function definitions.</p> Source code in <code>mirascope/cli/utils.py</code> <pre><code>def visit_FunctionDef(self, node):\n    \"\"\"Extracts decorators from function definitions.\"\"\"\n    for decorator in node.decorator_list:\n        self.decorators.append(ast.unparse(decorator))\n    self.generic_visit(node)\n</code></pre>"},{"location":"api/cli/utils/#mirascope.cli.utils.PromptAnalyzer.visit_Import","title":"<code>visit_Import(node)</code>","text":"<p>Extracts imports from the given node.</p> Source code in <code>mirascope/cli/utils.py</code> <pre><code>def visit_Import(self, node):\n    \"\"\"Extracts imports from the given node.\"\"\"\n    for alias in node.names:\n        self.imports.append(alias.name)\n    self.generic_visit(node)\n</code></pre>"},{"location":"api/cli/utils/#mirascope.cli.utils.PromptAnalyzer.visit_ImportFrom","title":"<code>visit_ImportFrom(node)</code>","text":"<p>Extracts from imports from the given node.</p> Source code in <code>mirascope/cli/utils.py</code> <pre><code>def visit_ImportFrom(self, node):\n    \"\"\"Extracts from imports from the given node.\"\"\"\n    for alias in node.names:\n        self.from_imports.append((node.module, alias.name))\n    self.generic_visit(node)\n</code></pre>"},{"location":"api/cli/utils/#mirascope.cli.utils.PromptAnalyzer.visit_Module","title":"<code>visit_Module(node)</code>","text":"<p>Extracts comments from the given node.</p> Source code in <code>mirascope/cli/utils.py</code> <pre><code>def visit_Module(self, node):\n    \"\"\"Extracts comments from the given node.\"\"\"\n    comments = ast.get_docstring(node)\n    self.comments = \"\" if comments is None else comments\n    self.generic_visit(node)\n</code></pre>"},{"location":"api/cli/utils/#mirascope.cli.utils.check_prompt_changed","title":"<code>check_prompt_changed(file1_path, file2_path)</code>","text":"<p>Checks if the given prompts have changed.</p> Source code in <code>mirascope/cli/utils.py</code> <pre><code>def check_prompt_changed(file1_path: Optional[str], file2_path: Optional[str]) -&gt; bool:\n    \"\"\"Checks if the given prompts have changed.\"\"\"\n    if file1_path is None or file2_path is None:\n        raise FileNotFoundError(\"Prompt or version file is missing.\")\n    # Parse the first file\n    try:\n        with open(file1_path, \"r\", encoding=\"utf-8\") as file:\n            content = file.read()\n    except FileNotFoundError as e:\n        raise FileNotFoundError(f\"The file {file1_path} was not found.\") from e\n    analyzer1 = PromptAnalyzer()\n    tree1 = ast.parse(content)\n    analyzer1.visit(tree1)\n\n    # Parse the second file\n    try:\n        with open(file2_path, \"r\", encoding=\"utf-8\") as file:\n            content = file.read()\n    except FileNotFoundError as e:\n        raise FileNotFoundError(f\"The file {file2_path} was not found.\") from e\n    analyzer2 = PromptAnalyzer()\n    tree2 = ast.parse(content)\n    analyzer2.visit(tree2)\n    # Compare the contents of the two files\n    differences = {\n        \"comments\": analyzer1.comments != analyzer2.comments,\n        \"imports_diff\": bool(set(analyzer1.imports) ^ set(analyzer2.imports)),\n        \"from_imports_diff\": bool(\n            set(analyzer1.from_imports) ^ set(analyzer2.from_imports)\n        ),\n        \"decorators_diff\": bool(set(analyzer1.decorators) ^ set(analyzer2.decorators)),\n        \"variables_diff\": set(analyzer1.variables.keys()) - ignore_variables\n        ^ set(analyzer2.variables.keys()) - ignore_variables,\n        \"classes_diff\": analyzer1.check_class_changed(analyzer2),\n        # Add other comparisons as needed\n    }\n    return any(differences.values())\n</code></pre>"},{"location":"api/cli/utils/#mirascope.cli.utils.check_status","title":"<code>check_status(mirascope_settings, directory)</code>","text":"<p>Checks the status of the given directory.</p> Source code in <code>mirascope/cli/utils.py</code> <pre><code>def check_status(\n    mirascope_settings: MirascopeSettings, directory: str\n) -&gt; Optional[str]:\n    \"\"\"Checks the status of the given directory.\"\"\"\n    version_directory_path = mirascope_settings.versions_location\n    prompt_directory_path = mirascope_settings.prompts_location\n    version_file_name = mirascope_settings.version_file_name\n    prompt_directory = os.path.join(version_directory_path, directory)\n    used_prompt_path = f\"{prompt_directory_path}/{directory}.py\"\n\n    # Get the currently used prompt version\n    versions = get_prompt_versions(f\"{prompt_directory}/{version_file_name}\")\n    if versions is None:\n        return used_prompt_path\n    current_head = versions.current_revision\n    if current_head is None:\n        return used_prompt_path\n    current_version_prompt_path = find_prompt_path(prompt_directory, current_head)\n\n    # Check if users prompt matches the current prompt version\n    has_file_changed = check_prompt_changed(\n        current_version_prompt_path, used_prompt_path\n    )\n    if has_file_changed:\n        return used_prompt_path\n    return None\n</code></pre>"},{"location":"api/cli/utils/#mirascope.cli.utils.find_prompt_path","title":"<code>find_prompt_path(directory, prefix)</code>","text":"<p>Finds and opens the prompt with the given directory.</p> Source code in <code>mirascope/cli/utils.py</code> <pre><code>def find_prompt_path(directory, prefix):\n    \"\"\"Finds and opens the prompt with the given directory.\"\"\"\n    pattern = os.path.join(directory, prefix + \"*.py\")\n    prompt_files = glob.glob(pattern)\n\n    if not prompt_files:\n        return None  # No files found\n\n    # Return first file found\n    return prompt_files[0]\n</code></pre>"},{"location":"api/cli/utils/#mirascope.cli.utils.get_prompt_versions","title":"<code>get_prompt_versions(version_file_path)</code>","text":"<p>Returns the versions of the given prompt.</p> Source code in <code>mirascope/cli/utils.py</code> <pre><code>def get_prompt_versions(version_file_path: str) -&gt; VersionTextFile:\n    \"\"\"Returns the versions of the given prompt.\"\"\"\n    versions = VersionTextFile()\n    try:\n        with open(version_file_path, \"r\", encoding=\"utf-8\") as file:\n            file.seek(0)\n            for line in file:\n                # Check if the current line contains the key\n                if line.startswith(CURRENT_REVISION_KEY + \"=\"):\n                    versions.current_revision = line.split(\"=\")[1].strip()\n                elif line.startswith(LATEST_REVISION_KEY + \"=\"):\n                    versions.latest_revision = line.split(\"=\")[1].strip()\n            return versions\n    except FileNotFoundError:\n        return versions\n</code></pre>"},{"location":"api/cli/utils/#mirascope.cli.utils.get_user_mirascope_settings","title":"<code>get_user_mirascope_settings(ini_file_path='mirascope.ini')</code>","text":"<p>Returns the user's mirascope settings.</p> Source code in <code>mirascope/cli/utils.py</code> <pre><code>def get_user_mirascope_settings(\n    ini_file_path: str = \"mirascope.ini\",\n) -&gt; MirascopeSettings:\n    \"\"\"Returns the user's mirascope settings.\"\"\"\n    config = ConfigParser()\n    config.read(ini_file_path)\n    return MirascopeSettings(**config[\"mirascope\"])\n</code></pre>"},{"location":"api/cli/utils/#mirascope.cli.utils.update_version_text_file","title":"<code>update_version_text_file(version_file, updates)</code>","text":"<p>Updates the version text file.</p> Source code in <code>mirascope/cli/utils.py</code> <pre><code>def update_version_text_file(version_file: str, updates: dict):\n    \"\"\"Updates the version text file.\"\"\"\n    try:\n        modified_lines = []\n        edits_made = {\n            key: False for key in updates\n        }  # Track which keys already exist in the file\n        version_file_path: Path = Path(version_file)\n        if not version_file_path.is_file():\n            version_file_path.touch()\n        # Read the file and apply updates\n        with open(version_file_path, \"r\", encoding=\"utf-8\") as file:\n            for line in file:\n                # Check if the current line contains any of the keys\n                for key, value in updates.items():\n                    if line.startswith(key + \"=\"):\n                        modified_lines.append(f\"{key}={value}\\n\")\n                        edits_made[key] = True\n                        break\n                else:\n                    # No key found, so keep the line as is\n                    modified_lines.append(line)\n\n            # Add any keys that were not found at the end of the file\n            for key, value in updates.items():\n                if not edits_made[key]:\n                    modified_lines.append(f\"{key}={value}\\n\")\n\n        # Write the modified content back to the file\n        with open(version_file_path, \"w\", encoding=\"utf-8\") as file:\n            file.writelines(modified_lines)\n    except FileNotFoundError:\n        print(f\"The file {version_file} was not found.\")\n    except IOError as e:\n        print(f\"An I/O error occurred: {e}\")\n</code></pre>"},{"location":"api/cli/utils/#mirascope.cli.utils.write_prompt_to_template","title":"<code>write_prompt_to_template(file, command, variables=None)</code>","text":"<p>Writes the given prompt to the template.</p> Source code in <code>mirascope/cli/utils.py</code> <pre><code>def write_prompt_to_template(\n    file: str,\n    command: Literal[MirascopeCommand.ADD, MirascopeCommand.USE],\n    variables: Optional[dict] = None,\n):\n    \"\"\"Writes the given prompt to the template.\"\"\"\n    mirascope_directory = get_user_mirascope_settings().mirascope_location\n    if variables is None:\n        variables = {}\n    template_loader = FileSystemLoader(searchpath=mirascope_directory)\n    template_env = Environment(loader=template_loader)\n    template = template_env.get_template(\"prompt_template.j2\")\n    analyzer = PromptAnalyzer()\n    tree = ast.parse(file)\n    analyzer.visit(tree)\n    if command == MirascopeCommand.ADD:\n        new_variables = variables | analyzer.variables\n    else:  # command == MirascopeCommand.USE\n        variables = dict.fromkeys(ignore_variables, None)\n        new_variables = {\n            k: analyzer.variables[k] for k in analyzer.variables if k not in variables\n        }\n\n    data = {\n        \"comments\": analyzer.comments,\n        \"variables\": new_variables,\n        \"imports\": analyzer.imports,\n        \"from_imports\": analyzer.from_imports,\n        \"classes\": analyzer.classes,\n    }\n    return template.render(**data)\n</code></pre>"},{"location":"concepts/llm_convenience_wrappers/","title":"LLM Convenience Wrappers","text":"<p>Mirascope provides convenience wrappers around the OpenAI client to make writing the code even more enjoyable. We purposefully pass <code>**kwargs</code> through our calls so that you always have direct access to their arguments.</p>"},{"location":"concepts/llm_convenience_wrappers/#why-should-you-care","title":"Why should you care?","text":"<ul> <li>Easy to learn         - There's no magic here -- it's just python         - Chaining is no different from writing basic python functions</li> <li>Convenient         - You could do it yourself -- and you still can -- but there's just something nice about calling <code>str(res)</code> to get the response content         - You only need to pass in a <code>Prompt</code> and we'll handle the rest</li> </ul>"},{"location":"concepts/llm_convenience_wrappers/#openaichat","title":"OpenAIChat","text":"<p>You can initialize an <code>OpenAIChat</code> instance and call <code>create</code> to generate an <code>OpenAIChatCompletion</code>:</p> <pre><code>from mirascope import OpenAIChat, Prompt\n\nclass RecipePrompt:\n        \"\"\"\n        Recommend recipes that use {ingredient} as an ingredient\n        \"\"\"\n\n        ingredient: str\n\nchat = OpenAIChat()\nres = chat.create(RecipePrompt(ingredient=\"apples\"))\nstr(res)  # returns the string content of the completion\n</code></pre>"},{"location":"concepts/llm_convenience_wrappers/#chaining","title":"Chaining","text":"<p>Adding a chain of calls is as simple as writing a function:</p> <pre><code>class ChefPrompt:\n        \"\"\"\n        Name the best chef in the world at cooking {food_type} food\n        \"\"\"\n\n        food_type: str\n\nclass RecipePrompt:\n        \"\"\"\n        Recommend a recipe that uses {ingredient} as an ingredient\n        that chef {chef} would serve in their restuarant\n        \"\"\"\n\n        ingredient: str\n        chef: str\n\ndef recipe_by_chef_using(ingredient: str, food_type: str) -&gt; str:\n        \"\"\"Returns a recipe using `ingredient`.\n\n        The recipe will be generated based on what dish using `ingredient`\n        the best chef in the world at cooking `food_type` might serve in\n        their restaurant\n        \"\"\"\n        chat = OpenAIChat()\n        chef_prompt = ChefPrompt(food_type=food_type)\n        chef = str(chat.create(chef_prompt))\n        recipe_prompt = RecipePrompt(ingredient=ingredient, chef=chef)\n        return str(chat.create(recipe_prompt)\n\nrecipe = recipe_by_chef_using(\"apples\", \"japanese\")\n</code></pre>"},{"location":"concepts/llm_convenience_wrappers/#streaming","title":"Streaming","text":"<p>You can use the <code>stream</code> method to stream a response. All this is doing is setting <code>stream=True</code> and providing the <code>OpenAIChatCompletionChunk</code> convenience wrappers around the response chunks.</p> <pre><code>chat = OpenAIChat()\nstream = chat.stream(prompt)\nfor chunk in stream:\n        print(str(chunk), end=\"\")\n</code></pre>"},{"location":"concepts/llm_convenience_wrappers/#openaichatcompletion","title":"OpenAIChatCompletion","text":"<p>The <code>OpenAIChatCompletion</code> class is a simple wrapper around the <code>ChatCompletion</code> class in <code>openai</code>. In fact, you can access everything from the original chunk as desired. The primary purpose of the class is to provide convenience.</p> <pre><code>completion = OpenAIChatCompletion(...)\n\ncompletion.completion  # ChatCompletion(...)\nstr(completion)        # original.choices[0].delta.content\ncompletion.choices     # original.choices\ncompletion.choice      # original.choices[0]\ncompletion.message     # original.choices[0].message\ncompletion.content     # original.choices[0].message.content\n</code></pre>"},{"location":"concepts/llm_convenience_wrappers/#openaichatcompletionchunk","title":"OpenAIChatCompletionChunk","text":"<p>Similarly the <code>OpenAIChatCompletionChunk</code> is a convenience wrapper around the <code>ChatCompletionChunk</code> class in <code>openai</code></p> <pre><code>chunk = OpenAIChatCompletionChunk(...)\n\nchunk.chunk    # ChatCompletionChunk(...)\nstr(chunk)     # original.choices[0].delta.content\nchunk.choices  # original.choices\nchunk.choice   # original.choices[0]\nchunk.delta    # original.choices[0].delta\nchunk.content  # original.choices[0].delta.content\n</code></pre>"},{"location":"concepts/llm_convenience_wrappers/#future-updates","title":"Future updates","text":"<p>There is a lot more to be added to the Mirascope models. Here is a list in no order of things we are thinking about adding next: </p> <ul> <li>tools as functions - decorator to write tools like normal functions</li> <li>additional models - support models beyond OpenAI</li> </ul> <p>If you want some of these features implemented or if you think something is useful but not on this list, let us know!</p>"},{"location":"concepts/mirascope_cli/","title":"Mirascope CLI","text":"<p>One of the main frustrations of dealing with prompts is keeping track of all the various versions. Taking inspiration from alembic and git, the mirascope cli provides a couple of key pieces of functionality to make managing prompts easier.</p>"},{"location":"concepts/mirascope_cli/#the-prompt-management-environment","title":"The prompt management environment","text":"<p>The first step to using the Mirascope CLI is to use the <code>init</code> command in your project's root directory.</p> <pre><code>mirascope init\n</code></pre> <p>This will create the directories and files to help manage prompts. Here is a sample structure created by the <code>init</code> function: <pre><code>|\n|-- mirascope.ini\n|-- mirascope\n|   |-- prompt_template.j2\n|   |-- versions/\n|   |   |-- &lt;directory_name&gt;/\n|   |   |   |-- version.txt\n|   |   |   |-- &lt;revision_id&gt;_&lt;directory_name&gt;.py\n|-- prompts/\n</code></pre></p> <p>Here is a rundown of each directory and file:</p> <ul> <li><code>mirascope.ini</code> - The INI file that can be customized for your project</li> <li><code>mirascope</code> - The default name of the directory that is home to the prompt management environment</li> <li><code>prompt_template.j2</code> - The Jinja2 template file that is used to generate prompt versions</li> <li><code>versions</code> - The directory that holds the various prompt versions</li> <li><code>versions/&lt;directory_name</code> - The sub-directory that is created for each prompt file in the <code>prompts</code> directory</li> <li><code>version.txt</code> - A file system method of keeping track of current and latest revisions. Coming soon is revision tracking using a database instead</li> <li><code>&lt;revision_id&gt;_&lt;directory_name&gt;.py</code> - A prompt version that is created by the <code>mirascope add</code> command, more on this later.</li> <li><code>prompts</code> - The user's prompt directory that stores all prompt files</li> </ul> <p>The directory names can be changed anytime by modifying the <code>mirascope.ini</code> file or when running the <code>init</code> command.</p> <pre><code>mirascope init --mirascope_location my_mirascope --prompts_location my_prompts\n</code></pre>"},{"location":"concepts/mirascope_cli/#saving-your-first-prompt","title":"Saving your first prompt","text":"<p>After creating the prompt management directory, you are now ready to build and iterate on some prompts. Begin by adding a Mirascope Prompt to the prompts directory.</p> <pre><code># prompts/my_prompt.py\nfrom mirascope import Prompt\n\nclass BookRecommendationPrompt(Prompt):\n    \"\"\"\n    Can you recommend some books on {topic} in a list format?\n    \"\"\"\n\n    topic: str\n</code></pre> <p>Once you are happy with the first iteration of this prompt, you can run:</p> <pre><code>mirascope add my_prompt\n</code></pre> <p>This will commit <code>my_prompt.py</code> to your <code>versions/</code> directory, creating a <code>my_prompt</code> sub-directory and a <code>0001_my_prompt.py</code>.</p> <p>Here is what <code>0001_my_prompt.py</code> will look like:</p> <pre><code># versions/my_prompt/0001_my_prompt.py\nfrom mirascope import Prompt\n\nprev_revision_id = \"None\"\nrevision_id = \"0001\"\n\nclass BookRecommendationPrompt(Prompt):\n    \"\"\"\n    Can you recommend some books on {topic} in a list format?\n    \"\"\"\n\n    topic: str\n</code></pre> <p>The prompt inside the versions directory is almost identical to the prompt inside the prompts directory with a few differences.</p> <p>The variables <code>prev_revision_id</code> and <code>revision_id</code> will be used for features coming soon, so stay tuned for updates.</p>"},{"location":"concepts/mirascope_cli/#iterating-on-the-prompt","title":"Iterating on the prompt","text":"<p>Now that this version of <code>my_prompt</code> has been saved, you are now free to modify the original <code>my_prompt.py</code> and iterate. Maybe, you want to add a system message to obtain advice from a professional.</p> <p>Here is what the next iteration of <code>my_prompt.py</code> will look like:</p> <pre><code># prompts/my_prompt.py\nfrom mirascope.prompts import Prompt, messages\n\n@messages\nclass BookRecommendationPrompt(Prompt):\n    \"\"\"\n        SYSTEM:\n        You are an expert in your field giving advice\n\n        USER:\n    Can you recommend some books on {topic} in a list format?\n    \"\"\"\n\n    topic: str\n</code></pre> <p>Before adding the next revision of <code>my_prompt</code>, you may want to check the status of your prompt.</p> <pre><code># You can specify a specific prompt\nmirascope status my_prompt\n\n# or, you can check the status of all prompts\nmirascope status\n</code></pre> <p>Note that status will be checked before the <code>add</code> or <code>use</code> command is run. Now we can run the same <code>add</code> command in the previous section to commit another version <code>0002_my_prompt.py</code></p>"},{"location":"concepts/mirascope_cli/#switching-between-versions","title":"Switching between versions","text":"<p>Often times when prompt engineering, you will want to try out different models with different prompts to obtain the best results.</p> <p>You can use the <code>use</code> command to quickly switch between the prompts:</p> <pre><code>mirascope use my_prompt 0001\n</code></pre> <p>Here you specify which prompt and also which version you want to use. This will update your <code>prompts/my_prompt.py</code> with the contents of <code>versions/0001_my_prompt.py</code> (minus the variables used internally).</p> <p>This will let you quickly swap prompts with no code change, the exception being when prompts have different properties.</p>"},{"location":"concepts/mirascope_cli/#future-updates","title":"Future updates","text":"<p>There is a lot more to be added to the Mirascope CLI. Here is a list in no order of things we are thinking about adding next: </p> <ul> <li>prompt comparison - A way to compare two different versions with a golden test</li> <li>remove - Remove a prompt</li> <li>history - View the revision history of a version</li> </ul> <p>If you want some of these features implemented or if you think something is useful but not on this list, let us know!</p>"},{"location":"concepts/pydantic_prompts/","title":"Pydantic Prompts","text":"<p>The <code>Prompt</code> class is the core of Mirascope, which extends Pydantic's <code>BaseModel</code>. The class leverages the power of python to make writing more complex prompts as easy and readable as possible. The docstring is automatically formatted as a prompt so that you can write prompts in the style of your codebase.</p>"},{"location":"concepts/pydantic_prompts/#why-should-you-care","title":"Why should you care?","text":"<ul> <li>You get all of the benefits of using Pydantic:<ul> <li>type hints, json schema, customization, ecosystem, production-grade</li> </ul> </li> <li>Speeds up development<ul> <li>Fewer bugs through validation</li> <li>Auto-complete, editor (and linter) support for errors</li> </ul> </li> <li>Easy to learn         - You only need to learn Pydantic</li> <li>Standardization and compatibility<ul> <li>Integrations with other libraries that use JSON Schema such as OpenAPI and FastAPI means writing less code.</li> </ul> </li> <li>Customization<ul> <li>Everything is Pydantic or basic python, so changing anything is as easy as overriding what you want to change</li> </ul> </li> <li>All of the above helps lead to production ready code</li> </ul>"},{"location":"concepts/pydantic_prompts/#the-prompt-class","title":"The <code>Prompt</code> Class","text":"<p>The docstring of the class acts as the prompt's template, and the attributes act as the template variables:</p> <pre><code>from mirascope import Prompt\n\nclass BookRecommendationPrompt(Prompt):\n    \"\"\"\n    Can you recommend some books on {topic}?\n    \"\"\"\n\n    topic: str\n\nprompt = BookRecommendationPrompt(topic=\"coding\")\nstr(prompt)\n</code></pre> <pre><code>Can you recommend some books on coding?\n</code></pre> <p>The <code>__str__</code> method, which formats all of the template variables, relies on the <code>template</code> function, which provides built-in string formatting so that you can write prettier docstrings. This means that longer prompts will still look well-formatted in your code base:</p> <pre><code>class LongerPrompt(Prompt):\n    \"\"\"\n    Longer prompts can be edited in a more organized format that looks\n    better in your code base. Any unwanted characters such as newlines\n    or tabs that are purely for text alignment and structure will be \n    automatically removed.\n\n    For newlines, just add one extra (e.g. 2 newlines -&gt; 1 newline here)\n\n        - The same goes for things you want indented\n    \"\"\"\n</code></pre> <p>Note</p> <p>If you want custom docstring formatting or none at all, simply override the <code>template</code> method.</p>"},{"location":"concepts/pydantic_prompts/#template-variables","title":"Template Variables","text":"<p>When you call <code>str(prompt)</code> the template will be formatted using the properties of the class that match the template variables. This means that you can define more complex properties through code. This is particularly useful when you want to inject template variables with custom formatting or template variables that depend on multiple attributes. </p> <pre><code>from mirascope import Prompt\n\nclass BookRecommendationPrompt(Prompt):\n    \"\"\"\n    Can you recommend some books on the following topic and genre pairs?\n\n        {topics_x_genres}\n    \"\"\"\n\n    topics: list[str]\n    genres: list[str]\n\n    @property\n    def topics_x_genres(self) -&gt; str:\n        \"\"\"Returns `topics` as a comma separated list.\"\"\"\n        return \"\\n\".join([\n                f\"Topic: {topic}, Genre: {genre}\"\n                for topic in topics\n                for genre in genre\n        ])\n\nprompt = BookRecommendationPrompt(\n    topics=[\"coding\", \"music\"], genres=[\"fiction\", \"fantasy\"]\n)\nstr(prompt)\n</code></pre> <pre><code>Can you recommend some books on the following topic and genre pairs?\n    Topic: coding, Genre: fiction\n    Topic: coding, Genre: fantasy\n    Topic: music, Genre: fiction\n    Topic: music, Genre fantasy\n</code></pre>"},{"location":"concepts/pydantic_prompts/#messages","title":"Messages","text":"<p>By default, the <code>Prompt</code> class treats the prompt template as a single user message. If you want to specify a list of messages instead, we provide a decorator to make this easy:</p> <pre><code>from mirascope.prompts import messages\n\n@messages  # decorator adds `messages` property to the class\nclass BookRecommendationPrompt(Prompt):\n    \"\"\"\n    SYSTEM:\n    You are the world's greatest librarian.\n\n    USER:\n    Can you recommend some books on {topic}?\n    \"\"\"\n\n    topic: str\n\nprompt = BookRecommendationPrompt(topic=\"coding\")\nprompt.messages\n</code></pre> <pre><code>[(\"system\", \"You are the world's greatest librarian\"), (\"user\", \"Can you recommend some books on coding?\")]\n</code></pre>"},{"location":"concepts/pydantic_prompts/#future-updates","title":"Future updates","text":"<p>There is a lot more to be added to Mirascope prompts. Here is a list in no order of things we are thinking about adding next: </p> <ul> <li>more complex prompts - handle more complex prompts for things like history</li> <li>testing for prompts - test the quality of your prompt input/output</li> <li>prompt response tracking - track the input/output when using a prompt</li> </ul> <p>If you want some of these features implemented or if you think something is useful but not on this list, let us know!</p>"},{"location":"cookbook/chaining/","title":"Chaining","text":"<p>Note</p> <p>Take a look at the code in our repo.</p> <p>Full walkthrough with explanations coming soon...</p>"},{"location":"cookbook/movie_bot/","title":"Movie Bot","text":"<p>Note</p> <p>Take a look at the code in our repo.</p> <p>Full walkthrough with explanations coming soon...</p>"},{"location":"cookbook/simple_call/","title":"A simple creation","text":"<p>Note</p> <p>Take a look at the code in our repo.</p> <p>Full walkthrough with explanations coming soon...</p>"}]}